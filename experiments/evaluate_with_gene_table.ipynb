{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Siamese BioBERT to create IR system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import requests\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.uniprot_loader import *\n",
    "from utils.annoy_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_HOST = '172.17.0.3'\n",
    "ES_PORT = '9200'\n",
    "EVAL_INDEX = 'disease_bert_no_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This setting is specific to Novartis machine as we need to connect to local host in this example. Thus, we will remove all env variable for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['http_proxy'] = \"\"\n",
    "os.environ['HTTP_PROXY'] = \"\"\n",
    "os.environ['https_proxy'] = \"\"\n",
    "os.environ['HTTPS_PROXY'] = \"\"\n",
    "os.environ['NO_PROXY'] = \"\"\n",
    "os.environ['no_proxy'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is only an example function for constructing input / output for table liked evaluation.\n",
    "If you only want to use this to query to the ElasticSearch or Annoy, please refer to the implemtation in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_like_input():\n",
    "    query_df = pd.read_csv('../data/devset/disease_eval_list_2.csv')\n",
    "    query_df = query_df[query_df['ambiguos'] == 0]\n",
    "    query_df['name'].to_csv('../data/devset/disease_table/disease.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    rows = []\n",
    "    cols = []\n",
    "    kg_label = []\n",
    "    kg_id = []\n",
    "    for ridx, row in query_df.reset_index().iterrows():\n",
    "        rows.append(ridx)\n",
    "        cols.append(0)\n",
    "        kg_label.append(row['name'])\n",
    "        kg_id.append(row['kgid'])\n",
    "        \n",
    "    truth_df = pd.DataFrame({\n",
    "        'row': rows,\n",
    "        'column': cols,\n",
    "        'kg_id': kg_id,\n",
    "        'kg_label': kg_label})\n",
    "    truth_df.to_csv('../data/devset/truth_disease_table/disease.tsv', sep='\\t', index=False)\n",
    "    return truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = create_table_like_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/devset/disease_table'\n",
    "truth_path = '../data/devset/truth_disease_table'\n",
    "filenames = glob.glob(data_file + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(filenames, generate_candidate_func, **kwargs):\n",
    "    prediction = dict()\n",
    "    for file in filenames:\n",
    "        basefile_name = os.path.basename(file)\n",
    "        prediction[basefile_name] = dict()\n",
    "        table = pd.read_csv(file, delimiter='\\t')\n",
    "        nrow = len(table)\n",
    "        ncol = len(table.columns)\n",
    "        answer_table = []\n",
    "        for i in range(nrow):\n",
    "            answer_table.append([])\n",
    "            for j in range(ncol):\n",
    "                answer_table[i].append([])\n",
    "\n",
    "        for ridx, row in table.iterrows():\n",
    "            for cidx, (colname, cell) in enumerate(row.items()):\n",
    "                if pd.isna(cell):\n",
    "                    continue\n",
    "                if isinstance(cell, float):\n",
    "                    continue\n",
    "                hits = generate_candidate_func(cell, **kwargs)\n",
    "                candidate_set = [hit[1] for hit in hits]\n",
    "                answer_table[ridx][cidx] = candidate_set\n",
    "        prediction[basefile_name] = answer_table\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(file, result, topk=3):\n",
    "    pred = result[file]\n",
    "    nrow = len(pred)\n",
    "    ncol = len(pred[0])\n",
    "    \n",
    "    gt_table = []\n",
    "    table = pd.read_csv(truth_path + '/' + file, delimiter='\\t')\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    non_empty_gt_idx = set()\n",
    "    stat = dict()\n",
    "    stat['prediction_log'] = []\n",
    "    for i in range(nrow):\n",
    "        gt_table.append([])\n",
    "        for j in range(ncol):\n",
    "            gt_table[i].append([])\n",
    "            \n",
    "    for _, row in table.iterrows():\n",
    "        cidx = row['column']\n",
    "        ridx = row['row']\n",
    "        cell_answer = row['kg_id']\n",
    "        if pd.notna(cell_answer):\n",
    "            gt_table[ridx][cidx].append(cell_answer)\n",
    "            non_empty_gt_idx.add((cidx,ridx))\n",
    "        \n",
    "    for ridx in range(nrow):\n",
    "        for cidx in range(ncol):\n",
    "            gt_set = set(gt_table[ridx][cidx])\n",
    "            answer_set = set(pred[ridx][cidx][:topk])\n",
    "            if answer_set and gt_set: \n",
    "                if answer_set.intersection(gt_set):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "                    stat['prediction_log'].append([table[ridx][cidx], answer_set])\n",
    "            elif answer_set:\n",
    "                fp += 1\n",
    "                stat['prediction_log'].append([table[ridx][cidx], answer_set])\n",
    "            elif gt_set:\n",
    "                fn += 1\n",
    "                stat['prediction_log'].append([table[ridx][cidx], answer_set])\n",
    "            else:\n",
    "                tn += 1\n",
    "    stat['tp'] = tp\n",
    "    stat['fp'] = fp\n",
    "    stat['fn'] = fn\n",
    "    stat['tn'] = tn\n",
    "    stat['topk'] = tp\n",
    "    stat['total'] = len(non_empty_gt_idx)\n",
    "    print(\"Top{}: {}/{}\".format(topk, tp, (len(non_empty_gt_idx))))\n",
    "    return stat, gt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_eval(filenames, generate_candidates_query_func, **kwargs):\n",
    "    eval_topk = [1,10]\n",
    "    if 'top_k' not in kwargs:\n",
    "        kwargs['top_k'] = 10\n",
    "    else:\n",
    "        eval_topk.append(kwargs['top_k'])\n",
    "    all_pred = get_prediction(filenames, generate_candidates_query_func, **kwargs)\n",
    "    \n",
    "    stat_topk = dict()\n",
    "    \n",
    "    for topk in eval_topk:\n",
    "        key = 'top_' + str(topk)\n",
    "        stat_topk[key] = []\n",
    "        for file in filenames:\n",
    "            basefile = os.path.basename(file)\n",
    "            stat, _ = evaluate(basefile, all_pred, topk)\n",
    "            stat_topk[key].append(stat)\n",
    "    return stat_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(filename, stat, extra_topk=None):\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['file', 'upperbound', 'top1', 'top10', 'topk', 'percent top1', 'percent top10', 'percent topk'])\n",
    "        count_upperbound = []\n",
    "        count_correct_top10 = []\n",
    "        count_correct_top1 = []\n",
    "        count_correct_topk = []\n",
    "        top10_stat = stat['top_10']\n",
    "        top1_stat = stat['top_1']\n",
    "        topk_stat = stat['top_{}'.format(extra_topk)] if extra_topk else None\n",
    "        \n",
    "        for i, file in enumerate(filenames):\n",
    "            if UPPER_BOUND_STAT[i]['topk'] != 0:\n",
    "                top10_percent = top10_stat[i]['topk']*100/UPPER_BOUND_STAT[i]['topk']\n",
    "                top1_percent = top1_stat[i]['topk']*100/UPPER_BOUND_STAT[i]['topk']\n",
    "                topk_value = topk_stat[i]['topk'] if topk_stat else 0\n",
    "                topk_percent = topk_value*100/UPPER_BOUND_STAT[i]['topk']\n",
    "                writer.writerow([os.path.basename(file), UPPER_BOUND_STAT[i]['topk'], top1_stat[i]['topk'], top10_stat[i]['topk'], topk_value, top1_percent, top10_percent, topk_percent])\n",
    "                count_upperbound.append(UPPER_BOUND_STAT[i]['topk'])\n",
    "                count_correct_top10.append(top10_stat[i]['topk'])\n",
    "                count_correct_top1.append(top1_stat[i]['topk'])\n",
    "                count_correct_topk.append(topk_value)\n",
    "        writer.writerow([\"Total\", np.sum(count_upperbound), np.sum(count_correct_top1), np.sum(count_correct_top10), np.sum(count_correct_topk) ,np.sum(count_correct_top1)/np.sum(count_upperbound), np.sum(count_correct_top10)/np.sum(count_upperbound), np.sum(count_correct_topk)/np.sum(count_upperbound)])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top53619: 154/162\n"
     ]
    }
   ],
   "source": [
    "disease_df = pd.read_csv('../uniprot_data_prep/disease_alias_label.tsv'.format(EVAL_INDEX), delimiter='\\t')\n",
    "corpus_disease = []\n",
    "for idx, row in disease_df.iterrows():\n",
    "    corpus_disease.append((row['name'], row['id']))\n",
    "\n",
    "def get_upper_bound_stat():\n",
    "    def return_whole_corpus_candidate(cell):\n",
    "        global corpus_disease\n",
    "        return corpus_disease\n",
    "\n",
    "    upper_bound_all_stat = []\n",
    "    for file in filenames:\n",
    "        pred_upperbound = get_prediction([file], return_whole_corpus_candidate)\n",
    "        basefile = os.path.basename(file)\n",
    "        stat, _ = evaluate(basefile, pred_upperbound, topk=len(corpus_disease))\n",
    "        upper_bound_all_stat.append(stat)\n",
    "    return upper_bound_all_stat\n",
    "\n",
    "UPPER_BOUND_STAT = get_upper_bound_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_ids = set(disease_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human_blood_group_systems_dbpv=2020-02_nif=table_ref=3_2_order=0.tsv\n",
      "Column: 3 Count: 2\n",
      "Column: 1 Count: 1\n",
      "Keratin_disease_dbpv=2020-02_nif=table_ref=1_2_order=0.tsv\n",
      "Column: 0 Count: 7\n",
      "Major_facilitator_superfamily_dbpv=2020-02_nif=table_ref=6.1_2_order=0.tsv\n",
      "Column: 3 Count: 10\n",
      "Potassium_channel_dbpv=2020-02_nif=table_ref=2_2_order=0.tsv\n",
      "Column: 2 Count: 1\n",
      "Cancer_syndrome_dbpv=2020-02_nif=table_ref=4_2_order=0.tsv\n",
      "Column: 0 Count: 8\n",
      "Distal_hereditary_motor_neuronopathies_dbpv=2020-02_nif=table_ref=1_2_order=0.tsv\n",
      "Column: 5 Count: 6\n",
      "Ciliopathy_dbpv=2020-02_nif=table_ref=4.1_2_order=0.tsv\n",
      "Column: 0 Count: 12\n",
      "List_of_therapeutic_monoclonal_antibodies_dbpv=2020-02_nif=table_ref=0_1_order=0.tsv\n",
      "Column: 6 Count: 76\n",
      "Column: 4 Count: 7\n",
      "Ciliopathy_dbpv=2020-02_nif=table_ref=4.3_2_order=0.tsv\n",
      "Column: 0 Count: 50\n",
      "Total for Main:  172\n",
      "Total:  180\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "sum_main = 0\n",
    "for i, file in enumerate(filenames):\n",
    "    basename = os.path.basename(file)\n",
    "    columns = dict()\n",
    "    if UPPER_BOUND_STAT[i]['topk'] != 0:\n",
    "        print(basename)\n",
    "        truth_df = pd.read_csv(os.path.join(truth_path, basename), delimiter='\\t')\n",
    "        seen = set()\n",
    "        for _, row in truth_df.iterrows():\n",
    "            if row['kg_id'] in disease_ids and pd.notna(row['kg_id']):\n",
    "                if (row['row'], row['column']) in seen:\n",
    "                    continue\n",
    "                seen.add((row['row'], row['column']))\n",
    "                count+=1\n",
    "                if row['column'] not in columns:\n",
    "                    columns[row['column']] = 0\n",
    "                columns[row['column']] += 1\n",
    "        for j, (col, total) in enumerate(sorted(columns.items(), key=lambda x:x[1], reverse=True)):\n",
    "            if j == 0:\n",
    "                sum_main += total\n",
    "            print(\"Column: {} Count: {}\".format(col, total))\n",
    "print(\"Total for Main: \", sum_main)\n",
    "print(\"Total: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Search Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([ {'host': '172.17.0.3', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q1001150</td>\n",
       "      <td>fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q100165995</td>\n",
       "      <td>acute pulmonary hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q1001920</td>\n",
       "      <td>hallucinogen persisting perception disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q1002195</td>\n",
       "      <td>autosomal recessive limb-girdle muscular dystr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q100270830</td>\n",
       "      <td>Benadryl challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53614</th>\n",
       "      <td>41068</td>\n",
       "      <td>Q998273</td>\n",
       "      <td>Polydactyly, Sex Reversal, Renal Hypoplasia, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53615</th>\n",
       "      <td>41069</td>\n",
       "      <td>Q998273</td>\n",
       "      <td>Smith Lemli Opitz syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53616</th>\n",
       "      <td>41070</td>\n",
       "      <td>Q998273</td>\n",
       "      <td>SMITH-LEMLI-OPITZ SYNDROME; SLOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53617</th>\n",
       "      <td>41071</td>\n",
       "      <td>Q998273</td>\n",
       "      <td>SLOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53618</th>\n",
       "      <td>41072</td>\n",
       "      <td>Q998273</td>\n",
       "      <td>7-dehydrocholesterol reductase deficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53619 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index          id                                               name\n",
       "0          0    Q1001150                                       fibrillation\n",
       "1          1  Q100165995                       acute pulmonary hypertension\n",
       "2          2    Q1001920        hallucinogen persisting perception disorder\n",
       "3          3    Q1002195  autosomal recessive limb-girdle muscular dystr...\n",
       "4          4  Q100270830                                 Benadryl challenge\n",
       "...      ...         ...                                                ...\n",
       "53614  41068     Q998273  Polydactyly, Sex Reversal, Renal Hypoplasia, a...\n",
       "53615  41069     Q998273                         Smith Lemli Opitz syndrome\n",
       "53616  41070     Q998273                   SMITH-LEMLI-OPITZ SYNDROME; SLOS\n",
       "53617  41071     Q998273                                               SLOS\n",
       "53618  41072     Q998273          7-dehydrocholesterol reductase deficiency\n",
       "\n",
       "[53619 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_es_embedding(corpus_df, index='', model=None):\n",
    "    mod_factor = len(corpus_df)//10\n",
    "    for idx, row in corpus_df.iterrows():\n",
    "        if idx % mod_factor == 0 or idx == len(corpus_df)-1:\n",
    "            print(idx*100/len(corpus_df))\n",
    "            \n",
    "        payload = dict()\n",
    "        payload['name'] = row['name'].strip()\n",
    "        payload['qid'] = row['id']\n",
    "\n",
    "        if model:\n",
    "            word_emb = model.encode(row['name'], device=device)\n",
    "            payload['word_embedding'] = word_emb\n",
    "            \n",
    "        try:\n",
    "            res = es.create(index=index, body=payload, id=str(idx))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query ElasticSearch with Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_elastic_search_fuzzy(keyword, **kwargs):\n",
    "    url = \"http://{}:{}/{}/_search\".format(ES_HOST, ES_PORT, EVAL_INDEX)\n",
    "    payload = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"match\" : {\n",
    "                \"name\" : {\n",
    "                    \"query\" : keyword,\n",
    "                    \"fuzziness\": \"auto\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        top_k = kwargs['top_k']\n",
    "        r = requests.get(url, json = payload)\n",
    "        hits = r.json()['hits']['hits']\n",
    "        hits = [(doc['_source']['name'], doc['_source']['qid']) for doc in hits[:top_k]]\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Elasticsearch with ElasticSearch Vector Field (Linear Scan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_elastic_search_with_embed(keyword, **kwargs):\n",
    "    if 'model' not in kwargs:\n",
    "        print(\"No Model Found, returning without querying ES\")\n",
    "        return []\n",
    "    model = kwargs['model']\n",
    "    top_k = kwargs['top_k'] if 'top_k' in kwargs else 10\n",
    "    url = \"http://{}:{}/{}/_search\".format(ES_HOST, ES_PORT, EVAL_INDEX)\n",
    "    vector = list(model.encode(str(keyword), device=device).astype(float))\n",
    "    payload = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\" : {\n",
    "                    \"match_all\" : {}\n",
    "                },\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'word_embedding') + 1.0\", \n",
    "                    \"params\": {\n",
    "                        \"query_vector\": vector\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, json = payload)\n",
    "        hits = r.json()['hits']['hits']\n",
    "        hits = [(doc['_source']['name'], doc['_source']['qid']) for doc in hits[:top_k]]\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Elasticsearch with Vector and Fuzzy Match\n",
    "\n",
    "This function will filter the search result using Fuzzy Match and then rerank them with Embedded vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_elastic_search_with_fuzzy_and_embed(keyword, **kwargs):\n",
    "    if 'model' not in kwargs:\n",
    "        print(\"No Model Found, returning without querying ES\")\n",
    "        return []\n",
    "    model = kwargs['model']\n",
    "    top_k = kwargs['top_k'] if 'top_k' in kwargs else 10\n",
    "    url = \"http://{}:{}/{}/_search\".format(ES_HOST, ES_PORT, EVAL_INDEX)\n",
    "    vector = list(model.encode(str(keyword), device=device).astype(float))\n",
    "    payload = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\" : {\n",
    "                    \"match\" : {\n",
    "                        \"name\" : {\n",
    "                            \"query\" : keyword,\n",
    "                            \"fuzziness\": \"auto\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'word_embedding') + 1.0\", \n",
    "                    \"params\": {\n",
    "                        \"query_vector\": vector\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, json = payload)\n",
    "        hits = r.json()['hits']['hits']\n",
    "        hits = [(doc['_source']['name'], doc['_source']['qid']) for doc in hits[:top_k]]\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query to Annoy\n",
    "To use Annoy as an indexed reference data, we need to first create annoy file and then issue the query to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_with_annoy(keyword, **kwargs):\n",
    "    model = kwargs['model']\n",
    "    annoy_object_wrapper = kwargs['annoy_object_wrapper']\n",
    "    id2name = kwargs['id2name']\n",
    "    top_k = kwargs['top_k']\n",
    "    name2id = kwargs['name2id']\n",
    "    \n",
    "    corpus_sentences = annoy_object_wrapper.embedding_object.corpus_sentences\n",
    "    corpus_embeddings = annoy_object_wrapper.embedding_object.corpus_embeddings\n",
    "    name_to_id = annoy_object_wrapper.embedding_object.name_to_id\n",
    "    annoy_index = annoy_object_wrapper.annoy_index\n",
    "\n",
    "    query_embedding = model.encode(str(keyword), device=device)\n",
    "\n",
    "    found_corpus_ids, scores = annoy_index.get_nns_by_vector(query_embedding, top_k, include_distances=True)\n",
    "    hits = []\n",
    "\n",
    "    for _id, score in zip(found_corpus_ids, scores):\n",
    "        # Cosine Distance is equivalent to Euclidean distance of normalized vectors = sqrt(2-2*cos(u, v))\n",
    "        # cosine_dist = sqrt(2-2*cos(u,v))\n",
    "        # Thus cos(u,v) = 1-(cosine_dist**2)/2\n",
    "        hits.append({'corpus_id': _id, 'score': 1 - ((score ** 2) / 2)})\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return_hits= []\n",
    "\n",
    "    for hit in hits:\n",
    "        name = corpus_sentences[hit['corpus_id']]\n",
    "        possible_id = name2id.get(corpus_sentences[hit['corpus_id']], [])\n",
    "        for _id in possible_id:\n",
    "            return_hits.append((name, _id))\n",
    "\n",
    "    return return_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q987664'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2id.get(annoy_object_wrapper.embedding_object.corpus_sentences[9267])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1001150'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(id2name.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-computed embeddings from disc\n"
     ]
    }
   ],
   "source": [
    "model = get_model('./siamese-biobert-disease-ep-1-Mar-29-2021-with-heuris-hard-neg-10')\n",
    "annoy_object_wrapper = AnnoyObjectWrapper(index_path='./wikidata-disease-embedding-4096-trees.ann', \n",
    "                          embedding_path='./wikidata-disease-768-embedding.pkl', \n",
    "                          reference_dataset_path='../uniprot_data_prep/{}_alias_label.tsv'.format(EVAL_INDEX), \n",
    "                          name2id_path='./wikidata-name2id-embedding-size-1500000', \n",
    "                          model=model, n_trees=4096, embedding_size=768, max_corpus_size=1500000)\n",
    "annoy_object_wrapper.create_embedding_and_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id2name(dataset_path):\n",
    "    all_name = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "    all_name = all_name.dropna() \n",
    "    \n",
    "    id2name = {}\n",
    "    for idx, row in all_name.iterrows():\n",
    "        if row['id'].strip() not in id2name:\n",
    "            id2name[row['id']] = set()\n",
    "        id2name[row['id']].add(row['name'].strip())\n",
    "        \n",
    "    return id2name\n",
    "\n",
    "\n",
    "def get_name2id(dataset_path):\n",
    "    all_name = pd.read_csv(dataset_path, delimiter='\\t')\n",
    "    all_name = all_name.dropna() \n",
    "    \n",
    "    name2id = {}\n",
    "    for idx, row in all_name.iterrows():\n",
    "        if row['name'].strip() not in name2id:\n",
    "            name2id[row['name']] = set()\n",
    "        name2id[row['name']].add(row['id'].strip())\n",
    "        \n",
    "    return name2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name = get_id2name('../uniprot_data_prep/{}_alias_label.tsv'.format(EVAL_INDEX))\n",
    "name2id = get_name2id('../uniprot_data_prep/{}_alias_label.tsv'.format(EVAL_INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_topk = predict_and_eval(filenames, generate_candidate_with_annoy, model=model, annoy_object_wrapper=annoy_object_wrapper, id2name=id2name, name2id=name2id)\n",
    "write_report('./annoy_report.csv', stat_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.read_csv('./annoy_report.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with interest model\n",
    "\n",
    "This section shows how we can evaluate each model in ElasticSearch. You can just pass query function to the predict_and_eval directly. For example, we pass `query_elastic_search_with_embed` into `predict_and_eval` to evaluate how the model perform using the vector we indexed in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    './siamese-biobert-disease-ep-1-Apr-16-2021-with-heuris-hard-neg-1',\n",
    "    './siamese-biobert-disease-ep-1-Apr-16-2021-with-heuris-hard-neg-2',\n",
    "    './siamese-biobert-disease-ep-1-Apr-16-2021-with-heuris-hard-neg-3',\n",
    "    './siamese-biobert-disease-ep-1-Apr-16-2021-with-heuris-hard-neg-4'\n",
    "]\n",
    "\n",
    "es_index_payload = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"qid\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"word_embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "all_pred_log = dict()\n",
    "\n",
    "for model_name in model_list:\n",
    "    basefile = os.path.basename(model_name)\n",
    "    EVAL_INDEX = basefile.lower()\n",
    "    print(EVAL_INDEX)\n",
    "    es.indices.create(\n",
    "        index=EVAL_INDEX,\n",
    "        body=es_index_payload,\n",
    "        ignore=400\n",
    "    )\n",
    "    model = get_model(model_name,device=device)\n",
    "    top_k=100\n",
    "    index_to_es_embedding(disease_df, index=EVAL_INDEX, model=model)\n",
    "    stat_topk = predict_and_eval(filenames, query_elastic_search_with_embed, model=model, top_k=top_k)\n",
    "    all_pred_log[model_name] = stat_topk\n",
    "    write_report('./es_vector_report/{}_top{}.csv'.format(EVAL_INDEX, top_k), stat_topk, extra_topk=top_k)\n",
    "    display(pd.read_csv('./es_vector_report/{}_top{}.csv'.format(EVAL_INDEX, top_k)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
